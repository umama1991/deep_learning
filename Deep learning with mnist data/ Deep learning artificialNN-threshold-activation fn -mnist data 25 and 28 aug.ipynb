{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa75f27e",
   "metadata": {},
   "source": [
    "# Deep learning\n",
    "-  The “deep” in “deep learning” isn’t a reference to any kind of deeper understanding achieved by the approach; rather, it stands for this idea of successive layers of representations. \n",
    "- Meanwhile, other approaches to machine learning tend to focus on learning only one or two layers of representations of the data (say, taking a pixel histogram and then applying a classification rule); hence, they’re sometimes called shallow learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ad4005",
   "metadata": {},
   "source": [
    "- loss function\n",
    "- fwd and bwd propagation\n",
    "- optimizer >>> adjust weight in reverse direction (bwd propagation)\n",
    "- threshold>> activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a1ac6f",
   "metadata": {},
   "source": [
    "## Artificial Neural Networks\n",
    "- using image data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d101540",
   "metadata": {},
   "source": [
    "### logistic regression \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "067685c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\hp\\anaconda3\\lib\\site-packages (2.13.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.13.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.24.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (67.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.57.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.29.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c8770c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a9806155",
   "metadata": {},
   "outputs": [],
   "source": [
    " from tensorflow.keras.datasets import mnist\n",
    " (train_images, train_labels), (test_images, test_labels) = mnist.load_data() #mnist list of numbers in form of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "844fcbc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0] #it is showing pixels value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0005ba1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3b3fba18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0a5a65c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image # python image learning called pillo \n",
    "#to see image\n",
    "im=Image.fromarray(train_images[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "264a66a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA/0lEQVR4nGNgGHhgPP/vfCMccgbv/vz58xa7nNnjv3/ev/xjyYYpxWXz4M/fP6dC/vytgggwIUnOPCDDwMBgxHOQQRdD0tibkfFQKeOL85OYGLG5ZTOPd6UoA8Pfz2gOVlv69+WFEAj775+lKHLsm/58cBeWgUkeRpG0/PPHHs5Blzz2dx+C8//vEWTX+hj834SQ/Pf/ArLG0D/PJOHWt//dxYMqeR8u1/znoTsDquREKMtg6Z+1DKgg7O9DCKPo3d9FaHIMoX9+TjKQDd308O/95RaYkn/+PL3+58+fI03oUgwMMsf//Pn758/LiZhSDAwMkg1//v7pVcUqR1cAAKxwbkTVIzd2AAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "66c48b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape  #60000 is depth or num of images 28 is x and 28 is y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5692f06c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image # python image learning called pillo \n",
    "#to see image\n",
    "km=Image.fromarray(train_images[0])\n",
    "km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7967ba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models \n",
    "from tensorflow.keras import layers\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(512, activation=\"relu\",input_shape=(28*28,))) #(28*28,))) 1 d array\n",
    "#relu and foftmax are activation function\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))#activation function =linearity to non linear\n",
    "#2 layers of sequential (added vertically)\n",
    "#layer 1 has 512 neurons\n",
    "#layer 2 has 10 neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4bb10c",
   "metadata": {},
   "source": [
    "## before fitting model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "86592f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical #onehotencoder\n",
    "test_labels_by_cat=to_categorical(test_labels)\n",
    "train_labels_by_cat=to_categorical(train_labels)\n",
    "train_labels_by_cat[0]\n",
    "#model.compile(optimizer=\"rmsprop\",loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"]) ab loss me sparse nhi aye ga"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b87a723",
   "metadata": {},
   "source": [
    " ## before fitting model must be compiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e8f2f960",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\",loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c1404b",
   "metadata": {},
   "source": [
    "model.compile(optimizer=\"rmsprop\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba1e521",
   "metadata": {},
   "source": [
    "## data must b e in the shape as the model require"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "726f016d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 784))\n",
    "train_images = train_images.astype(\"float32\") / 255 \n",
    "#image k pixels ki value 255 tk he. iski data ki range choti krne k liye max se devide kr diya\n",
    "#take model ka time kam lage data ko normalize kia he\n",
    "#answer float me aye ga\n",
    "test_images = test_images.reshape((10000, 784))\n",
    "test_images = test_images.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1c0622c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0].shape #reshaped in 1D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed23dc5",
   "metadata": {},
   "source": [
    "## Fitting / training the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "dab28c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "64289285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3020 - accuracy: 0.1110\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3017 - accuracy: 0.1112\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3016 - accuracy: 0.1114\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3017 - accuracy: 0.1119\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3016 - accuracy: 0.1120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x217109afd10>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels_by_cat, epochs=5, batch_size=128) \n",
    "#batch_size = no. of sample sample +learning size >> Varbose=0,calculation display nhi hogi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a43cc1d",
   "metadata": {},
   "source": [
    "## labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c8e78a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573dbae9",
   "metadata": {},
   "source": [
    "## model layers summery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "48808c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 512)               401920    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407050 (1.55 MB)\n",
      "Trainable params: 407050 (1.55 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b7fb4b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape #28*28 #from 3D to 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "12f20832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step\n"
     ]
    }
   ],
   "source": [
    "test_digits=test_images[0:10]\n",
    "pred=model.predict(test_digits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "034ffd56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.05712291e-08, 4.11770795e-09, 3.26115969e-06, 4.22440389e-05,\n",
       "        1.38881675e-11, 8.82598439e-09, 8.08801648e-13, 9.99953151e-01,\n",
       "        7.99315316e-08, 1.22859979e-06],\n",
       "       [9.46433403e-08, 4.26735869e-06, 9.99985456e-01, 8.55919825e-06,\n",
       "        3.29955735e-13, 7.98146758e-08, 7.53275557e-08, 3.83231641e-13,\n",
       "        1.42570900e-06, 2.97921925e-13],\n",
       "       [2.55809567e-07, 9.99486566e-01, 1.13463786e-04, 2.68450594e-06,\n",
       "        1.26638797e-05, 3.75364175e-06, 1.86124071e-05, 2.46163982e-04,\n",
       "        1.15602837e-04, 6.78239829e-08],\n",
       "       [9.99804556e-01, 5.83708193e-09, 2.56867156e-06, 4.28000021e-07,\n",
       "        8.08952700e-06, 1.27014471e-06, 1.68039784e-04, 8.94966342e-06,\n",
       "        3.48458995e-09, 6.22222024e-06],\n",
       "       [1.53938208e-06, 8.57050075e-09, 2.09135646e-06, 8.54391313e-09,\n",
       "        9.93193090e-01, 7.09852017e-08, 1.06645084e-05, 5.20772955e-05,\n",
       "        1.25787687e-06, 6.73911674e-03],\n",
       "       [6.18531937e-09, 9.99883294e-01, 6.43893884e-07, 6.44767368e-08,\n",
       "        1.60025775e-06, 5.52961454e-09, 2.66055835e-08, 1.10414898e-04,\n",
       "        3.94456538e-06, 2.06152651e-09],\n",
       "       [1.00958109e-09, 8.79523725e-07, 1.02227170e-06, 1.58198290e-07,\n",
       "        9.91659343e-01, 1.58794592e-05, 1.96398719e-06, 9.58687451e-05,\n",
       "        7.73796439e-03, 4.86994220e-04],\n",
       "       [1.29867237e-08, 1.41926660e-06, 6.86872299e-05, 8.32269609e-04,\n",
       "        1.74883884e-04, 1.26672580e-06, 1.49495027e-09, 4.41092416e-05,\n",
       "        4.17315960e-06, 9.98873174e-01],\n",
       "       [3.88236820e-09, 4.95278165e-08, 1.73959434e-05, 1.01238848e-08,\n",
       "        2.05970253e-04, 9.50608730e-01, 4.90490012e-02, 5.93380900e-09,\n",
       "        3.66094027e-05, 8.23044174e-05],\n",
       "       [1.93824023e-09, 3.16256812e-11, 3.22302274e-09, 6.58430054e-06,\n",
       "        3.74840130e-03, 5.97442584e-09, 1.01975491e-10, 1.23977021e-03,\n",
       "        2.29252866e-04, 9.94776011e-01]], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2d8b3df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.05712859e-08, 4.11771595e-09, 3.26115969e-06, 4.22440389e-05,\n",
       "        1.38881415e-11, 8.82600126e-09, 8.08804683e-13, 9.99953151e-01,\n",
       "        7.99316808e-08, 1.22859979e-06]], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test_digits[[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8caea0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b6480a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(test_digits[[0]])) #our data in 2 D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "349094c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c66a56c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "75eac5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0685 - accuracy: 0.9784\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5c65803c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAABCGlDQ1BJQ0MgUHJvZmlsZQAAeJxjYGA8wQAELAYMDLl5JUVB7k4KEZFRCuwPGBiBEAwSk4sLGHADoKpv1yBqL+viUYcLcKakFicD6Q9ArFIEtBxopAiQLZIOYWuA2EkQtg2IXV5SUAJkB4DYRSFBzkB2CpCtkY7ETkJiJxcUgdT3ANk2uTmlyQh3M/Ck5oUGA2kOIJZhKGYIYnBncAL5H6IkfxEDg8VXBgbmCQixpJkMDNtbGRgkbiHEVBYwMPC3MDBsO48QQ4RJQWJRIliIBYiZ0tIYGD4tZ2DgjWRgEL7AwMAVDQsIHG5TALvNnSEfCNMZchhSgSKeDHkMyQx6QJYRgwGDIYMZAKbWPz9HbOBQAAABcElEQVR4nO2VwY6DMAxEHRsaWv7/WysKsfcwYmSBVpv0vD4giMLk2WOMyC+hqiJSSsHj8/nMi7gxM2zgtr9jXVfc8B0zMzMRmaYJK9M04YCu4Gtxhru31iIC66/Xi5sHSGutkMMZpRQzgzo2gHGAtJTy+XygeAGJCAqhGvM8d4mSUc5SmBl4s+5A4iLi7kxTbjniPGBKMqAXFkV0d9xDvbVGxoGaquq2bRFBHDM7jiMiWOsM2xW5e+hDrRUND+ph2NYaGvtuBSRAPQabEyQpDFFVLG7b1iuXRWkreR+PR96Dx173ScqRwTmClWVZjuOQIfdba9idvxbIcaywN3rLekk/TyMq7vsu51joEnV3KrIHcJ3nGdYPfEhZ191hRSkFsDA9ImqtcnbCgKiqIkd+Re/3Ow8EEYF0r66ZsYhME6bxEVrQHYPNrZoNUdWBZsqwGfAiDUUUutexe5fkcYVj2LYDpETgr/j+U/pm/v/HF/EDOYjGMSUkvIoAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=28x28>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eight = Image.open('WhatsApp Image 2023-08-25 at 4.00.40 PM.jpeg') #WhatsApp Image 2023-08-25 at 4.00.40 PM= file name\n",
    "eight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4cb78729",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = eight.convert(\"L\")\n",
    "\n",
    "# Save the grayscale image\n",
    "image.save(\"grayscale_eight.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2d6c50a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   3,  10,   0,   0,   8,\n",
       "         15,   1,   1,   2,   0,  18,   0,   6,   0,   0,   8,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   1,   0,  34,   0,   3,\n",
       "          0,   0,   8,  14,   6,   0,   0,   9,  10,   2,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  11,   0, 255, 254,\n",
       "        255, 255, 238, 232,  14,   0,  15,   1,   0,  15,   2,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   4,   0, 241, 255,   0,\n",
       "          0,   8,  12, 255, 246,  13,   0,  18,   6,   0,   2,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 255, 255,   7,   5,\n",
       "          6,   0,   0,   0, 255,   0,   1,   0,  10,   0,   4,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 255, 230,   0,   0,   0,\n",
       "          2,   0,   9,   7,   2, 251,   2,  13,   0,   0,   2,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 255, 242,   9,  11,   4,\n",
       "          1,   0,   5,   5,   0, 255,   2,   0,   3,  12,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 255, 252, 255, 246,\n",
       "        255, 255, 254,   0,   7, 255,   0,   9,   0,   1,   5,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 254, 252,   0,  16,\n",
       "          0,   2, 255, 255, 245, 255,   0,   0,  11,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 255, 255,   0,  17,   0,\n",
       "          0,   4,   0,   0,   0, 240, 253,  15,   2,   0,   3,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 250,   0,  17,   2,   0,\n",
       "         14,   0,   5,   6,  12,   0, 255, 251,   0,   2,   8,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 255,   0,  10,   0,   9,\n",
       "          0,   6,   0,   0,   0,  18,   0, 244,   0,   1,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 255,   1,   8,   1,   0,\n",
       "         14,   0,  21,   0,  20,   0,   1, 255,   0,   0,   9,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 255,   0,   0,   7,   9,\n",
       "          1,   7,   0,   0,  12,   0,  13, 222,   9,   6,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 251,   0,   0,  16,   0,\n",
       "          0,   0,  11,   0,  10,   6,   0, 255,   0,   3,   8,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 253,   4,   7,   0,   5,\n",
       "         21,   0,   0,   2,   4,   0, 255, 251,   2,   5,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 249,  23,   0,   6,   0,\n",
       "          8,   0,  13,   7,   0, 255, 255,   0,   8,   7,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 255, 251,  10,   9,\n",
       "          1,  22,   0,   0, 251, 251,  16,   0,  13,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  12, 255, 243, 254,\n",
       "        244, 245, 255, 255,   0,  13,   0,   0,  14,   0,  16,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   6,   7,   0,  12,  18,\n",
       "          0,  13,   0,   0,  15,   0,  10,   3,   0,  21,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  13,  14,   0,\n",
       "         15,   0,   7,   0,   0,   0,  13,   0,   2,   0,  21,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   5,   0,   0,   6,\n",
       "          8,   0,   2,   9,   0,   8,   6,   0,  16,  17,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  10,   0,   0,  10,\n",
       "          0,  12,   1,   0,   2,   0,   0,  17,   0,   7,  10,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   8,  11,   0,\n",
       "          1,   5,   0,   3,   5,   6,   0,   0,   8,   0,   2,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eight_grey = Image.open('grayscale_eight.jpg')\n",
    "arr = np.asarray(eight_grey)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fc9deac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "99933c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr784 = arr.reshape(1,784) #for convert in2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "de8494d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(arr784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b5e9b4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(arr784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7ad26264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#or full code in one line\n",
    "np.argmax(model.predict(np.asarray(Image.open('grayscale_eight.jpg')).reshape(1,784)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd97491",
   "metadata": {},
   "source": [
    "### for image 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2290e305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAABCGlDQ1BJQ0MgUHJvZmlsZQAAeJxjYGA8wQAELAYMDLl5JUVB7k4KEZFRCuwPGBiBEAwSk4sLGHADoKpv1yBqL+viUYcLcKakFicD6Q9ArFIEtBxopAiQLZIOYWuA2EkQtg2IXV5SUAJkB4DYRSFBzkB2CpCtkY7ETkJiJxcUgdT3ANk2uTmlyQh3M/Ck5oUGA2kOIJZhKGYIYnBncAL5H6IkfxEDg8VXBgbmCQixpJkMDNtbGRgkbiHEVBYwMPC3MDBsO48QQ4RJQWJRIliIBYiZ0tIYGD4tZ2DgjWRgEL7AwMAVDQsIHG5TALvNnSEfCNMZchhSgSKeDHkMyQx6QJYRgwGDIYMZAKbWPz9HbOBQAAABtUlEQVR4nO1V2XLDIAzUAT7w/39rxglGfdjxljrO1O5z9yFDwFp0rITIBwzDoKpYqyrWZiYiKSXs4+88z59IznnNDJbjOILX3UVkWRYscHoVpRSywD7nfHDNzKZpwvVXeRk+zdydjtPH/rNfQGN3ByM8NTM4nlIys5zzDTf5KdjdPecsb0XDBVehqrXWiIiI5/MZEa/XKyJATXYW8CrGccQCGlJVM9u2LSLkZyopsl9wECPSJyLuXmvl6W1hpZRUtfdimiZVXdfVdqjqDfGbGeorIrRMKSHLIgLHwXs1fJaVCY0d0gnuqo8khapqra011Ad6QPi47LawYFZKYQaxHxHvzXaPEfa9GJCBYRhyzv2UuQQYsA4sGkgPqjoxVlW2CozZlNznotbK9Xns7GV31x2tNQYoIvM8w198yY5i9Usp56Qcju7eWosIaPNQk3VdOQFSSpy2J4nDMRZU9ePxgFPujgEKYfUiPTww30Be2D+y9wmuaa3VWkG3bRucyDn3k/A4qA67VAmGMcYoA+SLgifg4+jrJ27/S7y/H8uy9CGfz1PqkSH3meKp7COVR395pv7xN3wBPE+FrvGfqsEAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=28x28>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three = Image.open('three.jpeg') #checking model for new image\n",
    "three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "39c6b3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = three.convert(\"L\")\n",
    "\n",
    "# Save the grayscale image\n",
    "image.save(\"grayscale_three.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b60309a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#or full code in one line\n",
    "np.argmax(model.predict(np.asarray(Image.open('grayscale_three.jpg')).reshape(1,784)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dc945c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
